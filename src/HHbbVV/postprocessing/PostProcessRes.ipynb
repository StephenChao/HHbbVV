{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "\n",
    "from utils import CUT_MAX_VAL, ShapeVar\n",
    "from HHbbVV.hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    # res_samples,\n",
    "    # res_sig_keys,\n",
    "    nonres_samples,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    "    LUMI,\n",
    ")\n",
    "from postprocessing import res_shape_vars, load_filters\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "import hist\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_samples = OrderedDict()\n",
    "\n",
    "res_mps = [(900, 80), (1200, 190), (2000, 125), (3000, 250), (4000, 150)]\n",
    "\n",
    "for mX, mY in res_mps:\n",
    "    res_samples[f\"X[{mX}]->H(bb)Y[{mY}](VV)\"] = f\"NMSSM_XToYHTo2W2BTo4Q2B_MX-{mX}_MY-{mY}\"\n",
    "\n",
    "res_sig_keys = list(res_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del nonres_samples[\"VBFHHbbVV\"]\n",
    "nonres_sig_keys = [\"HHbbVV\", \"VBFHHbbVV\"]\n",
    "nonres_samples = {key: nonres_samples[key] for key in nonres_sig_keys}\n",
    "\n",
    "# bg_keys = [\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"]\n",
    "# samples = {key: samples[key] for key in [\"Data\"] + bg_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "samples_dir = MAIN_DIR / \"../data/skimmer/24Mar5AllYears\"\n",
    "# samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Jun10\"\n",
    "# res_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Apr11\"\n",
    "# samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/\"\n",
    "# res_signal_samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Apr11/\"\n",
    "year = \"2016\"\n",
    "\n",
    "date = \"24Mar6\"\n",
    "plot_dir = MAIN_DIR / f\"plots/PostProcessing/{date}/\"\n",
    "templates_dir = Path(f\"templates/{date}/\")\n",
    "\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/hists2d\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}/cutflows/{year}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GluGluToHHTobbVV_node_cHHH1                       : 100561 entries\n",
      "Loaded VBF_HHTobbVV_CV_1_C2V_1_C3_1                      : 9678 entries\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-900_MY-80              : 79014 entries\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-1200_MY-190            : 119555 entries\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-2000_MY-125            : 154938 entries\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-3000_MY-250            : 166706 entries\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-4000_MY-150            : 166511 entries\n",
      "Loaded QCD_HT300to500                                    : 8 entries\n",
      "Loaded QCD_HT700to1000                                   : 79891 entries\n",
      "Loaded QCD_HT1000to1500                                  : 54883 entries\n",
      "Loaded QCD_HT2000toInf                                   : 29965 entries\n",
      "Loaded QCD_HT1500to2000                                  : 65548 entries\n",
      "Loaded QCD_HT500to700                                    : 6597 entries\n",
      "Loaded TTToSemiLeptonic                                  : 563649 entries\n",
      "Loaded TTToHadronic                                      : 1012608 entries\n",
      "Loaded ST_t-channel_top_4f_InclusiveDecays               : 38358 entries\n",
      "Loaded ST_tW_top_5f_inclusiveDecays                      : 8839 entries\n",
      "Loaded ST_tW_antitop_5f_inclusiveDecays                  : 9586 entries\n",
      "Loaded ST_t-channel_antitop_4f_InclusiveDecays           : 19552 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/postprocessing.py:913: UserWarning: No events for WJetsToQQ_HT-200to400!\n",
      "  warnings.warn(f\"No events for {sample}!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded WJetsToQQ_HT-800toInf                             : 142130 entries\n",
      "Loaded WJetsToQQ_HT-600to800                             : 33598 entries\n",
      "Loaded WJetsToQQ_HT-400to600                             : 293 entries\n",
      "Loaded ZJetsToQQ_HT-200to400                             : 1 entries\n",
      "Loaded ZJetsToQQ_HT-400to600                             : 593 entries\n",
      "Loaded ZJetsToQQ_HT-600to800                             : 51577 entries\n",
      "Loaded ZJetsToQQ_HT-800toInf                             : 148021 entries\n",
      "Loaded WW                                                : 1894 entries\n",
      "Loaded ZZ                                                : 729 entries\n",
      "Loaded WZ                                                : 3146 entries\n",
      "Loaded GluGluHToBB                                       : 12018 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/postprocessing.py:905: UserWarning: No parquet directory for VBFHToBB!\n",
      "  warnings.warn(f\"No parquet directory for {sample}!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ZH_HToBB_ZToQQ                                    : 29277 entries\n",
      "Loaded WplusH_HToBB_WToQQ                                : 16362 entries\n",
      "Loaded WminusH_HToBB_WToQQ                               : 21367 entries\n",
      "Loaded ggZH_HToBB_ZToQQ                                  : 22517 entries\n",
      "Loaded ttHToBB                                           : 193853 entries\n",
      "Loaded VBFHToWWToAny_M-125_TuneCP5_withDipoleRecoil      : 72 entries\n",
      "Loaded HWminusJ_HToWW_M-125                              : 1386 entries\n",
      "Loaded GluGluHToWW_Pt-200ToInf_M-125                     : 652 entries\n",
      "Loaded HWplusJ_HToWW_M-125                               : 1841 entries\n",
      "Loaded ttHToNonbb_M125                                   : 52851 entries\n",
      "Loaded HZJ_HToWW_M-125                                   : 10787 entries\n",
      "Loaded JetHT_Run2016C_HIPM                               : 167582 entries\n",
      "Loaded JetHT_Run2016D_HIPM                               : 287156 entries\n",
      "Loaded JetHT_Run2016E_HIPM                               : 273569 entries\n",
      "Loaded JetHT_Run2016B_ver2_HIPM                          : 423991 entries\n",
      "Loaded JetHT_Run2016F_HIPM                               : 178714 entries\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'VBFHbb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m cutflow \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      5\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(samples\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(nonres_samples\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(res_samples\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m events_dict \u001b[38;5;241m=\u001b[39m postprocessing\u001b[38;5;241m.\u001b[39mload_samples(\n\u001b[1;32m      9\u001b[0m     samples_dir,\n\u001b[1;32m     10\u001b[0m     {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnonres_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mres_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msamples},\n\u001b[1;32m     11\u001b[0m     year,\n\u001b[1;32m     12\u001b[0m     load_filters,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_to_cutflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPreselection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinalWeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m cutflow\n",
      "File \u001b[0;32m~/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/utils.py:298\u001b[0m, in \u001b[0;36madd_to_cutflow\u001b[0;34m(events_dict, key, weight_key, cutflow)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_to_cutflow\u001b[39m(\n\u001b[1;32m    296\u001b[0m     events_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame], key: \u001b[38;5;28mstr\u001b[39m, weight_key: \u001b[38;5;28mstr\u001b[39m, cutflow: pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[1;32m    297\u001b[0m ):\n\u001b[0;32m--> 298\u001b[0m     cutflow[key] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    299\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(events_dict[sample][weight_key])\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(cutflow\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    300\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/utils.py:299\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_to_cutflow\u001b[39m(\n\u001b[1;32m    296\u001b[0m     events_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame], key: \u001b[38;5;28mstr\u001b[39m, weight_key: \u001b[38;5;28mstr\u001b[39m, cutflow: pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[1;32m    297\u001b[0m ):\n\u001b[1;32m    298\u001b[0m     cutflow[key] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 299\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(\u001b[43mevents_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m[weight_key])\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(cutflow\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    300\u001b[0m     ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VBFHbb'"
     ]
    }
   ],
   "source": [
    "systematics = {year: {}}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(\n",
    "    index=list(samples.keys()) + list(nonres_samples.keys()) + list(res_samples.keys())\n",
    ")\n",
    "\n",
    "events_dict = postprocessing.load_samples(\n",
    "    samples_dir,\n",
    "    {**nonres_samples, **res_samples, **samples},\n",
    "    year,\n",
    "    load_filters,\n",
    ")\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_parquet(f\"{sig_samples_dir}/{year}/GluGluToHHTobbVV_node_cHHH1/parquet\")\n",
    "events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.qcd_sf(events_dict, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "postprocessing.derive_variables(events_dict)\n",
    "cutflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = [\n",
    "    # ShapeVar(var=\"MET_pt\", label=r\"$p^{miss}_T$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"DijetEta\", label=r\"$\\eta^{jj}$\", bins=[30, -8, 8]),\n",
    "    # ShapeVar(var=\"DijetPt\", label=r\"$p_T^{jj}$ (GeV)\", bins=[30, 0, 750]),\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    # ShapeVar(var=\"bbFatJetEta\", label=r\"$\\eta^{bb}$\", bins=[20, -2.4, 2.4]),\n",
    "    ShapeVar(\n",
    "        var=\"bbFatJetPt\", label=r\"$p^{bb}_T$ (GeV)\", bins=[20, 300, 2300], significance_dir=\"right\"\n",
    "    ),\n",
    "    ShapeVar(\n",
    "        var=\"bbFatJetParticleNetMass\",\n",
    "        label=r\"$m^{bb}_{reg}$ (GeV)\",\n",
    "        bins=[20, 50, 250],\n",
    "        significance_dir=\"bin\",\n",
    "    ),\n",
    "    # ShapeVar(var=\"bbFatJetMsd\", label=r\"$m^{bb}_{msd}$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"bbFatJetParticleNetMD_Txbb\", label=r\"$T^{bb}_{Xbb}$\", bins=[50, 0.8, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetEta\", label=r\"$\\eta^{VV}$\", bins=[30, -2.4, 2.4]),\n",
    "    ShapeVar(var=\"VVFatJetPt\", label=r\"$p^{VV}_T$ (GeV)\", bins=[20, 300, 2300]),\n",
    "    ShapeVar(var=\"VVFatJetParticleNetMass\", label=r\"$m^{VV}_{reg}$ (GeV)\", bins=[20, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetMsd\", label=r\"$m^{VV}_{msd}$ (GeV)\", bins=[40, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetParticleNet_Th4q\", label=r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWW4q\", label=r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_probT\", label=r\"Prob(Top) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWWvsT\", label=r\"$T^{VV}_{HWW}$\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"bbFatJetPtOverDijetPt\", label=r\"$p^{bb}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverDijetPt\", label=r\"$p^{VV}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverbbFatJetPt\", label=r\"$p^{VV}_T / p^{bb}_T$\", bins=[50, 0.4, 2.0]),\n",
    "    # ShapeVar(var=\"nGoodMuonsHbb\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodMuonsHH\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectronsHbb\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectronsHH\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodJets\", label=r\"# of AK4 B-Jets\", bins=[5, 0, 5]),\n",
    "    # removed if not ggF nonresonant - needs to be the last variable!\n",
    "    # ShapeVar(var=\"BDTScore\", label=r\"BDT Score\", bins=[50, 0, 1]),\n",
    "]\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    plot_dir / f\"ControlPlots/{year}\",\n",
    "    year,\n",
    "    bg_keys=bg_keys,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e5, \"VBFHHbbVV\": 2e6} | {key: 2e4 for key in res_sig_keys},\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall LP SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import Region, nonres_shape_vars\n",
    "\n",
    "# temp region to check systematics\n",
    "selection_regions = {\n",
    "    \"pass\": Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.97, CUT_MAX_VAL],\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"lpsf\": Region(\n",
    "        cuts={\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        },\n",
    "        label=\"LP SF\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sel, cf = utils.make_selection(\n",
    "    selection_regions[\"lpsf\"].cuts, events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "\n",
    "sf_table = OrderedDict()\n",
    "\n",
    "for sig_key in tqdm(nonres_sig_keys + res_sig_keys):\n",
    "    systematics[sig_key] = {}\n",
    "    # calculate only for current year\n",
    "    events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "    lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "    # print(f\"BDT LP Scale Factor for {sig_key}: {lp_sf:.2f} ± {unc:.2f}\")\n",
    "    # print(uncs)\n",
    "\n",
    "    systematics[sig_key][\"lp_sf\"] = lp_sf\n",
    "    systematics[sig_key][\"lp_sf_unc\"] = unc / lp_sf\n",
    "\n",
    "    sf_table[sig_key] = {\"SF\": f\"{lp_sf:.2f} ± {unc:.2f}\", **uncs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.DataFrame(index=nonres_sig_keys + res_sig_keys)\n",
    "\n",
    "for key in sf_table[sig_key]:\n",
    "    sf_df[key] = [sf_table[skey][key] for skey in nonres_sig_keys + res_sig_keys]\n",
    "\n",
    "sf_df.to_clipboard()\n",
    "sf_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_regions = postprocessing.get_res_selection_regions(year)\n",
    "# del selection_regions[\"fail\"], selection_regions[\"failBlinded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    [\"HHbbVV\"],\n",
    "    # nonres_sig_keys + res_sig_keys,\n",
    "    # res_sig_keys,\n",
    "    selection_regions,\n",
    "    # res_shape_vars[:1],\n",
    "    nonres_shape_vars,\n",
    "    systematics,\n",
    "    templates_dir,\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"V+Jets\", \"Diboson\", \"Hbb\"],\n",
    "    plot_dir=plot_dir / \"templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e3, \"VBFHHbbVV\": 1e4} | {key: 1e2 for key in res_sig_keys},\n",
    "    # sig_splits=sig_splits[:2],\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    lpsfs=True,\n",
    "    plot_shifts=False,\n",
    "    pass_ylim=500,\n",
    "    fail_ylim=40000,\n",
    "    # blind_pass=True,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"]:  # + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        nonres_sig_keys,\n",
    "        selection_regions,\n",
    "        # res_selection_regions[year],\n",
    "        nonres_shape_vars,\n",
    "        # res_shape_vars,\n",
    "        systematics,\n",
    "        templates_dir,\n",
    "        plot_dir=plot_dir / \"templates\",\n",
    "        prev_cutflow=cutflow,\n",
    "        sig_scale_dict={\"HHbbVV\": 1e3, \"VBFHHbbVV\": 2e4} | {key: 1e2 for key in res_sig_keys},\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        lpsfs=True,\n",
    "        pass_ylim=500,\n",
    "        fail_ylim=40000,\n",
    "        # blind_pass=True,\n",
    "        show=False,\n",
    "        plot_shifts=True,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templates, f)\n",
    "\n",
    "with open(f\"{templates_dir}/systematics.json\", \"w\") as f:\n",
    "    json.dump(systematics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"templates/Apr10//2017_templates.pkl\", \"rb\") as f:\n",
    "    templates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates[\"pass\"].axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.hist2ds(\n",
    "    templates,\n",
    "    f\"{plot_dir}/templates/hists2d/\",\n",
    "    regions=[\"pass\", \"fail\", \"passBlinded\", \"failBlinded\"],\n",
    "    region_labels=selection_regions_label,\n",
    "    samples=[\"Data\", \"TT\", \"V+Jets\", \"X[3000]->H(bb)Y[190](VV)\"],\n",
    "    # fail_zlim=5e3,\n",
    "    # pass_zlim=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/{date}/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for year in years:\n",
    "    with open(f\"templates/Apr7//{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIG BTV OR Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbb2 = events_dict[\"HHbbVV\"][\n",
    "    np.all(events_dict[\"HHbbVV\"][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_txbbjet = np.argmax(hbb2[\"ak8FatJetParticleNetMD_Txbb\"].values, axis=1)\n",
    "higher_pt = np.argmax(hbb2[\"ak8FatJetPt\"].values, axis=1)\n",
    "higher_mpnet = np.argmax(hbb2[\"ak8FatJetParticleNetMass\"].values, axis=1)\n",
    "print(\n",
    "    \"higher txbb sorting\",\n",
    "    np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_txbbjet]),\n",
    ")\n",
    "print(\"higher pt sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_pt]))\n",
    "print(\"higher eta sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_pt]))\n",
    "print(\n",
    "    \"higher mpnet sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_mpnet])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in events_dict:\n",
    "    print(sample)\n",
    "    print(\n",
    "        np.mean(\n",
    "            np.all(events_dict[sample][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "            * (events_dict[sample][\"VVFatJetParTMD_THWWvsT\"].values.squeeze() > 0.6)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(\n",
    "    np.all(events_dict[\"HHbbVV\"][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "    * (events_dict[\"HHbbVV\"][\"VVFatJetParTMD_THWWvsT\"].values.squeeze() > 0.6)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
